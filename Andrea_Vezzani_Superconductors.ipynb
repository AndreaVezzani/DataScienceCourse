{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esplorazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('superconductors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50,figsize=(40,40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling delle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "x_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(x_scaled, columns=list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.hist(bins=50,figsize=(40,40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df_scaled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,40))\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.iloc[:, df_scaled.columns != 'critical_temp'].corrwith(df_scaled['critical_temp']).plot.bar(figsize= (20,10),title=\"Corr\", fontsize=10, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimozione features non correlate con la temp crit o autocorrelate tra loro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(style=\"ticks\")\n",
    "#sns.pairplot(df[[\"std_ThermalConductivity\",\"range_atomic_radius\",\"range_ThermalConductivity\",\"wtd_std_ThermalConductivity\",\"critical_temp\"]], corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_matrix = cor.abs()\n",
    "#upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "#to_drop = [column for column in upper.columns if ( any(upper[column] > 0.90) or upper['critical_temp'][column] < 0.1 )]\n",
    "#df_scaled.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = cor.abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop=[]\n",
    "for column in upper.columns:\n",
    "    if upper['critical_temp'][column] < 0.1:\n",
    "        to_drop.append(column)\n",
    "    else:\n",
    "        for column1 in upper.columns:\n",
    "            if upper[column][column1] > 0.9:\n",
    "                if upper['critical_temp'][column] > upper['critical_temp'][column1]:\n",
    "                    to_drop.append(column1)\n",
    "                else:\n",
    "                    to_drop.append(column)\n",
    "df_scaled.drop(to_drop, axis=1, inplace=True)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,40))\n",
    "cor1 = df_scaled.corr()\n",
    "sns.heatmap(cor1, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.iloc[:, df_scaled.columns != 'critical_temp'].corrwith(df_scaled['critical_temp']).plot.bar(figsize= (20,10),title=\"Corr\", fontsize=10, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_scaled.iloc[:, df_scaled.columns != 'critical_temp'].corrwith(df_scaled['critical_temp'])).sort_values().tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('critical_temp',axis=1)\n",
    "y = df_scaled['critical_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR':LinearRegression(),'KNN':neighbors.KNeighborsRegressor(),\n",
    "         'RF':RandomForestRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(X,y,i):\n",
    "    keys=[]\n",
    "    mean_squared_errors = []\n",
    "    R2_scores = []\n",
    "    features = X.columns\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    \n",
    "    for k,v in models.items():\n",
    "        model = v\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        R2_scores.append(r2_score(y_test,pred))\n",
    "        mean_squared_errors.append(mean_squared_error(y_test,pred))\n",
    "        keys.append(k)\n",
    "    table = pd.DataFrame({'model':keys, 'RMSE':mean_squared_errors,'R2 score':R2_scores})\n",
    "    table['RMSE'] = table['RMSE'].apply(lambda x: np.sqrt(x))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance(X,y,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.Series(RF.predict(X_test))\n",
    "y_pred_train = pd.Series(RF.predict(X_train))\n",
    "\n",
    "rmse = round(np.sqrt(mean_squared_error(y_test,y_pred_test)),4)\n",
    "r2 = round(r2_score(y_pred_test,y_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "y_pred_test = y_pred_test.dropna()\n",
    "y_pred_train = y_pred_train.dropna()\n",
    "y_test = y_test.dropna()\n",
    "y_train = y_train.dropna()\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(y_test,y_pred_test)\n",
    "line = slope*y_test+intercept\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(y_test,line,color='red')\n",
    "plt.scatter(y_test,y_pred_test)\n",
    "plt.ylabel('Predicted Temp',fontsize=20)\n",
    "plt.xlabel('Actual Temp',fontsize=20)\n",
    "text = r'$\\pm'+str(rmse)+'$'+'\\n r2 score: ' +str(r2)\n",
    "plt.text(-0.1,1.7,'RMSE: '+text,fontsize=15)\n",
    "plt.title('Actual Temperature vs Predicted Temp',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['critical_temp', 'wtd_std_ThermalConductivity', 'range_atomic_radius', 'wtd_mean_Valence', 'wtd_entropy_atomic_mass' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_scaled[lista]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una clusterizzazione più naturale sarebbe dividere i campioni in \"lowT\" e \"highT\", tuttavia la confusione nella distribuzione è tale per cui una separazione dei campioni ad alta T avviene creando 3 cluster. Il primo contiene i compioni a bassissima T, il secondo è un cluster di transizione e il terzo contiene i campioni ad alta T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans3 = KMeans(3)\n",
    "kmeans3.fit(data)\n",
    "clusters3 = kmeans3.fit_predict(data)\n",
    "data['cluster3']=clusters3\n",
    "data['critical_temp'].hist(by=data['cluster3'], bins= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in [0,1,2]:\n",
    "    a=data['critical_temp'][(data[\"cluster3\"] == i)].mean()\n",
    "    c=data['critical_temp'][(data[\"cluster3\"] == i)].median()\n",
    "    list1.append(a)\n",
    "    list1.append(c)\n",
    "    \n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lowT = data[(data[\"cluster3\"] == 0)]\n",
    "data_middleT = data[(data[\"cluster3\"] == 2)]\n",
    "data_highT = data[(data[\"cluster3\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = data_lowT.drop('critical_temp',axis=1)\n",
    "y_1 = data_lowT['critical_temp']\n",
    "model_performance(X_1,y_1,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = data_middleT.drop('critical_temp',axis=1)\n",
    "y_2 = data_middleT['critical_temp']\n",
    "model_performance(X_2,y_2,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = data_highT.drop('critical_temp',axis=1)\n",
    "y_3 = data_highT['critical_temp']\n",
    "model_performance(X_3,y_3,42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clusterizzazione migliora significativamente le performance nei primi due cluster, ma la peggiora nel terzo. Questo perché i primi due cluster sono più concentrati attorno ad un valore, mentre il terzo cluster ha una distribuzione molto larga. A causa della riduzione significativa del numero di variabili predittive, il valore r2 subisce un drastico abbassamento in tutti i cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
